{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Based RNN Tutorial\n",
    "### by Zachary Pulliam\n",
    "\n",
    "This notebook walks through the steps that are taken in train.py and test.py to both train and test the model. Hyperparameters for training and testing that will be used to create the model, determine learning rate, determine number of epochs, etc., should be located under the files 'train_args.json' and 'test_args.json.' Within the files, the RNN architecture can be determined as well and should match when tetsing a previously trained model. Model hyperparamertes will be save prior to training at the location specified for the model to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages needed\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "# local imports\n",
    "from datasets import CharDataset, WordDataset\n",
    "from rnn import RNN\n",
    "from train import train\n",
    "from test import test\n",
    "\n",
    "# set device: GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Define working directory and text file to learn from \"\"\"\n",
    "\n",
    "folder = \"path/to/cwd\"  # working directory\n",
    "txt_file = \"path/to/data/tiny-shakespeare.txt\"  # text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Create dataset class \"\"\"\n",
    "\n",
    "dataset = CharDataset(txt_file, device)  # CharDataset for character based, WordDataset for word based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load parameters for training specified in train_args.json \"\"\"\n",
    "\n",
    "with open(os.path.join(folder, 'hyps/train_args.json')) as json_file:\n",
    "    args = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Create model based on vocab_size, specified hidden_size, and specified num_layers \"\"\"\n",
    "\n",
    "rnn = RNN(dataset.vocab_size, dataset.vocab_size, args['hidden_size'], args['num_layers']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Train the model \"\"\"\n",
    "\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load parameters for testing specified in test_args.json \"\"\"\n",
    "\n",
    "with open(os.path.join(folder, 'test_args.json')) as json_file:\n",
    "    args = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Test the model \"\"\"\n",
    "\n",
    "test(args)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e94b4907ea06e8ffc00a1152b131f23416fcb01c909f4f699ab56243ba961803"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
